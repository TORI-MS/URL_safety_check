import streamlit as st
import pandas as pd
import joblib
import numpy as np
import re
from urllib.parse import urlparse
import matplotlib.pyplot as plt
import seaborn as sns

# ---------------------------
# ëª¨ë¸ & ë°ì´í„° ë¡œë“œ
# ---------------------------
model = joblib.load("phishing_model.joblib")   # â† joblib ë²„ì „ìœ¼ë¡œ êµì²´
known_urls = pd.read_csv("famous_url_with_alias.csv")  # ì¸ì¦ëœ URL ëª©ë¡
dataset = pd.read_csv("dataset_phishing.csv")  # ì›ë³¸ ë°ì´í„°ì…‹ (ë¶„ì„ìš©)
X = dataset.drop(columns=["url", "status"])

# ---------------------------
# Feature Extraction Function
# ---------------------------
def extract_features(url: str):
    """dataset_phishing.csv ê¸°ë°˜ feature ì¶”ì¶œ (ê°„ì†Œí™” ë²„ì „)"""
    parsed = urlparse(url)
    hostname = parsed.netloc or ""
    path = parsed.path or ""

    length_url = len(url)
    length_hostname = len(hostname)

    nb_dots = url.count(".")
    nb_hyphens = url.count("-")
    nb_at = url.count("@")
    nb_qm = url.count("?")
    nb_and = url.count("&")
    nb_or = url.count("|")
    nb_eq = url.count("=")
    nb_underscore = url.count("_")
    nb_tilde = url.count("~")
    nb_percent = url.count("%")
    nb_slash = url.count("/")
    nb_star = url.count("*")
    nb_colon = url.count(":")
    nb_comma = url.count(",")
    nb_semicolumn = url.count(";")
    nb_dollar = url.count("$")
    nb_space = url.count(" ")
    nb_www = url.count("www")
    nb_com = url.count(".com")
    nb_dslash = url.count("//")

    http_in_path = 1 if "http" in path else 0
    https_token = 1 if "https" in url else 0

    ratio_digits_url = sum(c.isdigit() for c in url) / length_url if length_url > 0 else 0
    ratio_digits_host = sum(c.isdigit() for c in hostname) / length_hostname if length_hostname > 0 else 0

    punycode = 1 if "xn--" in hostname else 0
    prefix_suffix = 1 if "-" in hostname else 0
    random_domain = 0
    tld_in_path = 1 if re.search(r"\.[a-z]{2,}$", path) else 0
    tld_in_subdomain = 1 if re.search(r"\.[a-z]{2,}$", hostname.split(".")[0]) else 0
    abnormal_subdomain = 1 if hostname.count(".") > 3 else 0
    nb_subdomains = len(hostname.split(".")) - 2 if hostname else 0

    # ë‚˜ë¨¸ì§€ëŠ” ê¸°ë³¸ê°’ ì²˜ë¦¬
    dummy = np.zeros(len(X.columns) - 25)  

    features = [
        length_url, length_hostname,
        0,  # ip
        nb_dots, nb_hyphens, nb_at, nb_qm, nb_and, nb_or, nb_eq,
        nb_underscore, nb_tilde, nb_percent, nb_slash, nb_star,
        nb_colon, nb_comma, nb_semicolumn, nb_dollar, nb_space,
        nb_www, nb_com, nb_dslash,
        http_in_path, https_token,
        ratio_digits_url, ratio_digits_host,
        punycode, 0,  # port
        tld_in_path, tld_in_subdomain, abnormal_subdomain,
        nb_subdomains, prefix_suffix, random_domain
    ] + dummy.tolist()

    return np.array(features, dtype=float)

# ---------------------------
# Streamlit UI
# ---------------------------
st.title("ğŸ” í”¼ì‹± URL íƒì§€ê¸°")

user_url = st.text_input("ê²€ì‚¬í•  URLì„ ì…ë ¥í•˜ì„¸ìš”:")

if user_url:
    # 1. ì¸ì¦ëœ URL ì²´í¬
    if user_url in known_urls["url"].values:
        st.success("âœ… ì¸ì¦ëœ ì•ˆì „í•œ URLì…ë‹ˆë‹¤.")
    else:
        # 2. íŠ¹ì§• ì¶”ì¶œ & ì˜ˆì¸¡
        features = extract_features(user_url)
        pred = model.predict([features])[0]

        if pred == "phishing":
            st.error("ğŸš¨ í”¼ì‹± ìœ„í—˜ URLë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.success("âœ… ì•ˆì „í•œ URLë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ---------------------------
        # ğŸ“Š ë¶„ì„ ë° ì„¤ëª…
        # ---------------------------
        st.subheader("ğŸ“Š ë¶„ì„ ê·¼ê±°")

        # (1) Feature ì¤‘ìš”ë„ (ì „ì²´ ëª¨ë¸ ê¸°ì¤€)
        st.markdown("**ëª¨ë¸ì´ í•™ìŠµí•œ ì£¼ìš” íŠ¹ì§• ì¤‘ìš”ë„**")
        importances = model.feature_importances_
        indices = np.argsort(importances)[-15:]
        plt.figure(figsize=(6,5))
        sns.barplot(x=importances[indices], y=np.array(X.columns)[indices])
        plt.title("ì£¼ìš” Feature ì¤‘ìš”ë„")
        st.pyplot(plt)

        # (2) ì…ë ¥ URL ê°’ ë¹„êµ
        st.markdown("**ì…ë ¥ URLì˜ íŠ¹ì§• ê°’ì´ ì •ìƒ í‰ê· ê³¼ í”¼ì‹± í‰ê·  ì¤‘ ì–´ë””ì— ê°€ê¹Œìš´ì§€**")
        legit_mean = dataset[dataset["status"]=="legitimate"].drop(columns=["url","status"]).mean()
        phish_mean = dataset[dataset["status"]=="phishing"].drop(columns=["url","status"]).mean()

        explanation = []
        for i, col in enumerate(X.columns[:30]):  # ì²˜ìŒ 30ê°œë§Œ ë¹„êµ
            val = features[i]
            if abs(val - phish_mean[col]) < abs(val - legit_mean[col]):
                explanation.append(f"ğŸ”´ {col} ê°’({val:.2f}) â†’ í”¼ì‹± í‰ê· ({phish_mean[col]:.2f})ì— ë” ê°€ê¹Œì›€")
            else:
                explanation.append(f"ğŸŸ¢ {col} ê°’({val:.2f}) â†’ ì •ìƒ í‰ê· ({legit_mean[col]:.2f})ì— ë” ê°€ê¹Œì›€")

        for exp in explanation[:10]:  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
            st.write(exp)
